{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94052d7cf91a998",
   "metadata": {},
   "source": [
    "# Tiny Dataset notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "base_path = f\"{os.getcwd()}\"\n",
    "\n",
    "file_path = os.path.join(os.path.dirname(base_path), 'data/ctg-studies-tiny.db')\n",
    "\n",
    "conn = sqlite3.connect(file_path)\n",
    "\n",
    "query = \"SELECT * FROM tiny_dataset\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "# data_summary = df.describe().to_string() use a summary of the data to pass to LM\n",
    "data = df.head()\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\":f\"Can you summarize this data?{data}\" # Replace this with a different initial prompt in desired.\n",
    "}]\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Keeps the conversational context intact\n",
    "assistant_response = response.choices[0].message.content\n",
    "print(assistant_response)\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": assistant_response\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f96c0cbc19d3a",
   "metadata": {},
   "source": [
    "### Continue the conversation\n",
    "Replace the content of the `new_user_message` variable with different prompts to continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963e28fdc783ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_message = \"Is there anything interesting I should know bout this data?\"\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": new_user_message\n",
    "})\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "assistant_response = response.choices[0].message.content\n",
    "print(assistant_response)\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": assistant_response\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346f0386e68f4f7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
