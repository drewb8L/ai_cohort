{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94052d7cf91a998",
   "metadata": {},
   "source": [
    "# Tiny Dataset notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0832350dd3f64c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:39:41.107456Z",
     "start_time": "2024-10-22T21:39:38.123479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run completed!\n",
      "({'study_purpose': 0.464, 'study_background': 0.464, 'demographics': 0.002, 'outcomes': 0.04, 'complications': 0.026, 'jazz_hands': 0.004}, 0.249, [[1.0, 0.465, 0.0, 0.0, 0.0, 0.0], [0.465, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]], 0.751)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import openai\n",
    "from freeplay import Freeplay, RecordPayload, CallInfo, ResponseInfo, SessionInfo, CallInfo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPEN_AI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "FREEPLAY_API_KEY = os.environ.get(\"FREEPLAY_API_KEY\")\n",
    "\n",
    "\n",
    "# create your a freeplay client object\n",
    "fpClient = Freeplay(\n",
    "    freeplay_api_key=os.getenv(\"FREEPLAY_API_KEY\"),\n",
    "    api_base=\"https://8thlight.freeplay.ai/api\"\n",
    ")\n",
    "\n",
    "## PROMPT FETCH ##\n",
    "# set the prompt variables\n",
    "prompt_vars = {\"keyA\": \"valueA\"}\n",
    "# get a formatted prompt\n",
    "formatted_prompt = fpClient.prompts.get_formatted(project_id=\"473ef06b-2883-41da-85dd-9ccec95c95c6\",\n",
    "                                                  template_name=\"Evaluation of Summary Capabilities\",\n",
    "                                                  environment=\"latest\",\n",
    "                                                  variables=prompt_vars)\n",
    "\n",
    "assistant_messages = [message for message in formatted_prompt.messages if message['role'] == \"assistant\"]\n",
    "\n",
    "file_path = '/Users/kroy/ai-cohort/ai_cohort/data/ctg-studies-tiny.csv'\n",
    "\n",
    "test_file = openai.files.create(\n",
    "    file=open(file_path, \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "my_assistant = openai.beta.assistants.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=getattr(formatted_prompt, \"system_content\"),\n",
    "    name=\"Data Analysis Chatbot\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "          \"file_ids\": [test_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "my_thread = openai.beta.threads.create()\n",
    "\n",
    "my_thread_message = openai.beta.threads.messages.create(\n",
    "  thread_id=my_thread.id,\n",
    "  role=\"user\",\n",
    "  content=assistant_messages[0][\"content\"],\n",
    "  attachments=[\n",
    "    {\n",
    "      \"file_id\": test_file.id,\n",
    "      \"tools\": [\n",
    "        { \"type\": \"code_interpreter\" }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "my_run = openai.beta.threads.runs.create(\n",
    "  thread_id=my_thread.id,\n",
    "  assistant_id=my_assistant.id,\n",
    ")\n",
    "\n",
    "keep_retrieving_run = openai.beta.threads.runs.retrieve(\n",
    "    thread_id=my_thread.id,\n",
    "    run_id=my_run.id\n",
    ")\n",
    "\n",
    "run_steps = openai.beta.threads.runs.steps.list(\n",
    "  thread_id=my_thread.id,\n",
    "  run_id=my_run.id\n",
    ")\n",
    "\n",
    "def pollAnswers(threadId, runId):\n",
    "        completed = False\n",
    "        start = time.time()\n",
    "        while not completed:\n",
    "            try:\n",
    "                response = openai.beta.threads.runs.retrieve(\n",
    "                    thread_id=threadId,\n",
    "                    run_id=runId\n",
    "                )\n",
    "\n",
    "                if response.status == 'completed':\n",
    "                    end = time.time()\n",
    "                    print('Run completed!')\n",
    "                    respmsg = openai.beta.threads.messages.list(threadId)\n",
    "                    print(respmsg.data[0].content[0].text.value)\n",
    "                    outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "                    completed = True\n",
    "\n",
    "                    # # add the response to your message set\n",
    "                    all_messages = formatted_prompt.all_messages(\n",
    "                        {'role': respmsg.data[0].role,\n",
    "                         'content': respmsg.data[0].content[0].text.value}\n",
    "                    )\n",
    "                    \n",
    "                    # ## RECORD ##\n",
    "                    # # create a session\n",
    "                    session = fpClient.sessions.create()\n",
    "                    \n",
    "                    # # build the record payload\n",
    "                    payload = RecordPayload(\n",
    "                        all_messages=all_messages,\n",
    "                        inputs=prompt_vars,\n",
    "                        session_info=session,\n",
    "                        prompt_info=formatted_prompt.prompt_info,\n",
    "                        call_info=CallInfo.from_prompt_info(formatted_prompt.prompt_info, start_time=start, end_time=end),\n",
    "                        response_info=ResponseInfo(\n",
    "                            is_complete=completed\n",
    "                        )\n",
    "                    )\n",
    "                    # record the LLM interaction\n",
    "                    fpClient.recordings.create(payload)\n",
    "                    \n",
    "                    # bstack.emit('chat.message', {'message': outgoingMessages})\n",
    "                    break\n",
    "\n",
    "                if response.status == 'expired':\n",
    "                    print('Task expired!')\n",
    "                    respmsg = openai.beta.threads.messages.list(threadId)\n",
    "                    print(respmsg.data[0].content[0].text.value)\n",
    "\n",
    "                    outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "                    completed = True\n",
    "                    # bstack.emit('chat.message', {'message': outgoingMessages})\n",
    "                    break\n",
    "\n",
    "                if response.status == 'requires_action':\n",
    "                    print('Run Action Required!')\n",
    "\n",
    "                    tool_outputs = []\n",
    "                    for ra in response.required_action.submit_tool_outputs.tool_calls:\n",
    "                        if ra.type == 'function' and ra.function.name in functions:\n",
    "                            print(f'Running {ra.function.name} with arguments {ra.function.arguments}')\n",
    "                            ret = functions[ra.function.name](ra.function.arguments)\n",
    "                            print('Returned', ret)\n",
    "                            tool_outputs.append({\n",
    "                                'tool_call_id': ra.id,\n",
    "                                'output': json.dumps(ret)\n",
    "                            })\n",
    "                        else:\n",
    "                            tool_outputs.append({\n",
    "                                'tool_call_id': ra.id,\n",
    "                                'output': 'There is a problem, function not found!'\n",
    "                            })\n",
    "\n",
    "                    run = openai.beta.threads.runs.submitToolOutputs(\n",
    "                        threadId,\n",
    "                        runId,\n",
    "                        {'tool_outputs': tool_outputs}\n",
    "                    )\n",
    "\n",
    "                if response.status in ('failed', 'cancelled', 'expired', 'cancelling'):\n",
    "                    print(f'Completed {response.status}')\n",
    "                    completed = True\n",
    "                    break\n",
    "\n",
    "                if response.status in ('in_progress', 'queued'):\n",
    "                    print(f'Run {response.status}')\n",
    "                    time.sleep(2)  # Poll every 2 seconds\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error in polling (retrying):', str(e))\n",
    "                # Handle the exception or retry logic as necessary\n",
    "\n",
    "pollAnswers(my_thread.id, my_run.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
