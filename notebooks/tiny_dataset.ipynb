{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94052d7cf91a998",
   "metadata": {},
   "source": [
    "# Tiny Dataset notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data provided is a summary of clinical studies with various attributes such as study ID, completion date, study type, eligibility, and demographic details among others. Here is a summarized overview of five specific clinical studies within the dataset:\n",
      "\n",
      "1. **NCT00436514** (Sequence 286365)\n",
      "   - **Completion**: July 2009 (Actual)\n",
      "   - **Summary**: Focused on colorectal cancer, being a frequent cause of death particularly in Europe.\n",
      "   - **Description**: Not provided.\n",
      "   - **Condition**: Colorectal Cancer\n",
      "   - **Study Type**: Interventional\n",
      "   - **Eligibility**: Adults aged 18 to 80 years.\n",
      "   - **Volunteers**: Not accepting healthy volunteers.\n",
      "   - **Sex**: All\n",
      "   - **Age Range**: 18 to 80 years\n",
      "   - **References**: Includes a derived citation (PMID: 21039676).\n",
      "\n",
      "2. **NCT02827617** (Sequence 150334)\n",
      "   - **Completion**: Expected by December 31, 2024 (Estimated)\n",
      "   - **Summary**: Aims to identify new prognostic factors for chronic lymphocytic leukemia.\n",
      "   - **Description**: Focuses on the implications of TP53 mutations in the chemoimmunotherapy era.\n",
      "   - **Condition**: Chronic Lymphocytic Leukemia\n",
      "   - **Study Type**: Observational\n",
      "   - **Eligibility**: Adult male and female participants. \n",
      "   - **Volunteers**: Not accepting healthy volunteers.\n",
      "   - **Sex**: All\n",
      "   - **Age Range**: Minimum 18 years, maximum not specified.\n",
      "   - **References**: None provided.\n",
      "\n",
      "3. **NCT01559311** (Sequence 467550)\n",
      "   - **Completion**: April 2016 (Actual)\n",
      "   - **Summary**: Evaluates clinical outcomes for subjects diagnosed with bradycardia.\n",
      "   - **Description**: Includes all eligible patients providing written consent.\n",
      "   - **Condition**: Bradycardia\n",
      "   - **Study Type**: Interventional\n",
      "   - **Eligibility**: Patients meeting current bradycardia indications.\n",
      "   - **Volunteers**: Not accepting healthy volunteers.\n",
      "   - **Sex**: All\n",
      "   - **Age Range**: Minimum 18 years, maximum not specified.\n",
      "   - **References**: None.\n",
      "\n",
      "4. **NCT00744393** (Sequence 214610)\n",
      "   - **Completion**: December 2009 (Estimated)\n",
      "   - **Summary**: Investigates how sleep is disrupted in critically ill mechanically ventilated ICU patients.\n",
      "   - **Description**: Details sleep disruptions experienced by ICU patients on mechanical ventilation.\n",
      "   - **Condition**: Mechanically Ventilated ICU Patients\n",
      "   - **Study Type**: Interventional\n",
      "   - **Eligibility**: Adults aged 18 years or older, mechanically ventilated.\n",
      "   - **Volunteers**: Not accepting healthy volunteers.\n",
      "   - **Sex**: All\n",
      "   - **Age Range**: Minimum 18 years, maximum not specified.\n",
      "   - **References**: None.\n",
      "\n",
      "5. **NCT01168349** (Sequence 417884)\n",
      "   - **Completion**: December 2010 (Actual)\n",
      "   - **Summary**: Observes the clinical management and outcomes of anemia in patients with neoplasms.\n",
      "   - **Description**: Not provided.\n",
      "   - **Condition**: Anemia, Neoplasms\n",
      "   - **Study Type**: Observational\n",
      "   - **Eligibility**: Adult patients aged 18 years or older.\n",
      "   - **Volunteers**: Not accepting healthy volunteers.\n",
      "   - **Sex**: All\n",
      "   - **Age Range**: Minimum 18 years, maximum not specified.\n",
      "   - **References**: None.\n",
      "\n",
      "This dataset encapsulates vital information regarding the registration, design, participant demographics, and operational details pertinent to various studies, facilitating a broad understanding of ongoing and completed research in different medical and health-related fields.\n"
     ]
    }
   ],
   "source": [
    "# import sqlite3\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import openai\n",
    "# from freeplay import Freeplay \n",
    "# from dotenv import load_dotenv\n",
    "# \n",
    "# load_dotenv()\n",
    "# \n",
    "# openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# OPEN_AI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# FREEPLAY_API_KEY = os.environ.get(\"FREEPLAY_API_KEY\")\n",
    "# \n",
    "# fp_client = Freeplay(\n",
    "#     provider_config=ProviderConfig(openai=OpenAIConfig(OPENAI_API_KEY)),\n",
    "#     freeplay_api_key=FREEPLAY_API_KEY,\n",
    "#     api_base=f'https://8thlight.freeplay.ai/api'\n",
    "# )\n",
    "# \n",
    "# prompt_vars = {\"keyA\": \"valueA\"}\n",
    "# completion = fp_client.get_cpmpletion(project_id='AI_Cohort_1_Group_3_Explorations',\n",
    "#                                       template_name=\"Evaluation of Summary Capabilities\",\n",
    "#                                       variables=prompt_vars)\n",
    "# \n",
    "# \n",
    "# base_path = f\"{os.getcwd()}\"\n",
    "# \n",
    "# file_path = os.path.join(os.path.dirname(base_path), 'data/ctg-studies-tiny.db')\n",
    "# \n",
    "# conn = sqlite3.connect(file_path)\n",
    "# \n",
    "# query = \"SELECT * FROM tiny_dataset\"\n",
    "# df = pd.read_sql_query(query, conn)\n",
    "# # data_summary = df.describe().to_string() use a summary of the data to pass to LM\n",
    "# data = df.head()\n",
    "# \n",
    "# \n",
    "# messages = \n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4-turbo\",\n",
    "#     messages=messages\n",
    "# )\n",
    "# \n",
    "# # Keeps the conversational context intact\n",
    "# assistant_response = response.choices[0].message.content\n",
    "# print(assistant_response)\n",
    "# messages.append({\n",
    "#     \"role\": \"assistant\",\n",
    "#     \"content\": assistant_response\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97b7be3d0c78ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5f96c0cbc19d3a",
   "metadata": {},
   "source": [
    "### Continue the conversation\n",
    "Replace the content of the `new_user_message` variable with different prompts to continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963e28fdc783ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_user_message = \"Is there anything interesting I should know bout this data?\"\n",
    "# \n",
    "# messages.append({\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": new_user_message\n",
    "# })\n",
    "# \n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4-turbo\",\n",
    "#     messages=messages\n",
    "# )\n",
    "# assistant_response = response.choices[0].message.content\n",
    "# print(assistant_response)\n",
    "# messages.append({\n",
    "#     \"role\": \"assistant\",\n",
    "#     \"content\": assistant_response\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346f0386e68f4f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0832350dd3f64c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:39:41.107456Z",
     "start_time": "2024-10-22T21:39:38.123479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run in_progress\n",
      "Run completed!\n",
      "Here are the first few entries from the `summary` column:\n",
      "\n",
      "1. **Row 0**: \"Colorectal cancer is one of the most frequent ...\"\n",
      "2. **Row 1**: \"The general aim of the project is the identifi...\"\n",
      "3. **Row 2**: \"The purpose of this clinical project is to eva...\"\n",
      "4. **Row 3**: \"The purpose of this study is to determine what...\"\n",
      "5. **Row 4**: \"This observational study will evaluate the cli...\"\n",
      "\n",
      "If you need a more detailed review or have specific areas you want to expand on, please let me know!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import openai\n",
    "from freeplay import Freeplay, RecordPayload, CallInfo, ResponseInfo, SessionInfo, CallInfo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPEN_AI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "FREEPLAY_API_KEY = os.environ.get(\"FREEPLAY_API_KEY\")\n",
    "\n",
    "\n",
    "# create your a freeplay client object\n",
    "fpClient = Freeplay(\n",
    "    freeplay_api_key=os.getenv(\"FREEPLAY_API_KEY\"),\n",
    "    api_base=\"https://8thlight.freeplay.ai/api\"\n",
    ")\n",
    "\n",
    "## PROMPT FETCH ##\n",
    "# set the prompt variables\n",
    "prompt_vars = {\"keyA\": \"valueA\"}\n",
    "# get a formatted prompt\n",
    "formatted_prompt = fpClient.prompts.get_formatted(project_id=\"473ef06b-2883-41da-85dd-9ccec95c95c6\",\n",
    "                                                  template_name=\"Evaluation of Summary Capabilities\",\n",
    "                                                  environment=\"latest\",\n",
    "                                                  variables=prompt_vars)\n",
    "# print(getattr(formatted_prompt, \"messages\"))\n",
    "assistant_messages = [message for message in formatted_prompt.messages if message['role'] == \"assistant\"]\n",
    "# print(assistant_messages)\n",
    "\n",
    "## LLM CALL ##\n",
    "# Make an LLM call to your provider of choice\n",
    "# start = time.time()\n",
    "# chat_response =  openai.chat.completions.create(\n",
    "#     model=formatted_prompt.prompt_info.model,\n",
    "#     messages=formatted_prompt.messages,\n",
    "#     **formatted_prompt.prompt_info.model_parameters\n",
    "# )\n",
    "# end = time.time()\n",
    "\n",
    "# # add the response to your message set\n",
    "# all_messages = formatted_prompt.all_messages(\n",
    "#     {'role': chat_response.choices[0].message.role,\n",
    "#      'content': chat_response.choices[0].message.content}\n",
    "# )\n",
    "\n",
    "# ## RECORD ##\n",
    "# # create a session\n",
    "# session = fpClient.sessions.create()\n",
    "\n",
    "# # build the record payload\n",
    "# payload = RecordPayload(\n",
    "#     all_messages=all_messages,\n",
    "#     inputs=prompt_vars,\n",
    "#     session_info=session,\n",
    "#     prompt_info=formatted_prompt.prompt_info,\n",
    "#     call_info=CallInfo.from_prompt_info(formatted_prompt.prompt_info, start_time=start, end_time=end),\n",
    "#     response_info=ResponseInfo(\n",
    "#         is_complete=chat_response.choices[0].finish_reason == 'stop'\n",
    "#     )\n",
    "# )\n",
    "# # record the LLM interaction\n",
    "# fpClient.recordings.create(payload)\n",
    "\n",
    "# \n",
    "file_path = '/Users/kroy/ai-cohort/ai_cohort/data/ctg-studies-tiny.csv'\n",
    "\n",
    "test_file = openai.files.create(\n",
    "    file=open(file_path, \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "my_assistant = openai.beta.assistants.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=getattr(formatted_prompt, \"system_content\"),\n",
    "    name=\"Data Analysis Chatbot\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "          \"file_ids\": [test_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "my_thread = openai.beta.threads.create()\n",
    "\n",
    "my_thread_message = openai.beta.threads.messages.create(\n",
    "  thread_id=my_thread.id,\n",
    "  role=\"user\",\n",
    "  content=assistant_messages[0][\"content\"],\n",
    "  attachments=[\n",
    "    {\n",
    "      \"file_id\": test_file.id,\n",
    "      \"tools\": [\n",
    "        { \"type\": \"code_interpreter\" }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "my_run = openai.beta.threads.runs.create(\n",
    "  thread_id=my_thread.id,\n",
    "  assistant_id=my_assistant.id,\n",
    ")\n",
    "\n",
    "keep_retrieving_run = openai.beta.threads.runs.retrieve(\n",
    "    thread_id=my_thread.id,\n",
    "    run_id=my_run.id\n",
    ")\n",
    "\n",
    "run_steps = openai.beta.threads.runs.steps.list(\n",
    "  thread_id=my_thread.id,\n",
    "  run_id=my_run.id\n",
    ")\n",
    "\n",
    "# if response.status == 'completed':\n",
    "#                     print('Run completed!')\n",
    "#                     respmsg = self.openai.beta.threads.messages.list(threadId)\n",
    "#                     print(respmsg.data[0].content[0].text.value)\n",
    "\n",
    "#                     outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "\n",
    "# respmsg = openai.beta.threads.messages.list(my_thread.id)\n",
    "# print(respmsg)\n",
    "# outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "# print(run_steps)\n",
    "def pollAnswers(threadId, runId):\n",
    "        completed = False\n",
    "        start = time.time()\n",
    "        while not completed:\n",
    "            try:\n",
    "                response = openai.beta.threads.runs.retrieve(\n",
    "                    thread_id=threadId,\n",
    "                    run_id=runId\n",
    "                )\n",
    "\n",
    "                # bstack.emit(\n",
    "                #     'status.update',\n",
    "                #     {\n",
    "                #         'status': response.status,\n",
    "                #         'id': response.id,\n",
    "                #         'created_at': response.created_at,\n",
    "                #         'completed_at': response.completed_at\n",
    "                #     }\n",
    "                # )\n",
    "\n",
    "                if response.status == 'completed':\n",
    "                    end = time.time()\n",
    "                    print('Run completed!')\n",
    "                    respmsg = openai.beta.threads.messages.list(threadId)\n",
    "                    print(respmsg.data[0].content[0].text.value)\n",
    "\n",
    "                    # Make an LLM call to your provider of choice\n",
    "                    # chat_response =  openai.chat.completions.create(\n",
    "                    #     model=formatted_prompt.prompt_info.model,\n",
    "                    #     messages=formatted_prompt.messages,\n",
    "                    #     **formatted_prompt.prompt_info.model_parameters\n",
    "                    # )\n",
    "                    \n",
    "                    \n",
    "                    # # add the response to your message set\n",
    "                    all_messages = formatted_prompt.all_messages(\n",
    "                        {'role': respmsg.data[0].role,\n",
    "                         'content': respmsg.data[0].content[0].text.value}\n",
    "                    )\n",
    "                    \n",
    "                    # ## RECORD ##\n",
    "                    # # create a session\n",
    "                    session = fpClient.sessions.create()\n",
    "                    \n",
    "                    # # build the record payload\n",
    "                    payload = RecordPayload(\n",
    "                        all_messages=all_messages,\n",
    "                        inputs=prompt_vars,\n",
    "                        session_info=session,\n",
    "                        prompt_info=formatted_prompt.prompt_info,\n",
    "                        call_info=CallInfo.from_prompt_info(formatted_prompt.prompt_info, start_time=start, end_time=end),\n",
    "                        response_info=ResponseInfo(\n",
    "                            is_complete=chat_response.choices[0].finish_reason == 'stop'\n",
    "                        )\n",
    "                    )\n",
    "                    # record the LLM interaction\n",
    "                    fpClient.recordings.create(payload)\n",
    "                    \n",
    "\n",
    "                    outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "                    completed = True\n",
    "                    # bstack.emit('chat.message', {'message': outgoingMessages})\n",
    "                    break\n",
    "\n",
    "                if response.status == 'expired':\n",
    "                    print('Task expired!')\n",
    "                    respmsg = openai.beta.threads.messages.list(threadId)\n",
    "                    print(respmsg.data[0].content[0].text.value)\n",
    "\n",
    "                    outgoingMessages = respmsg.data[0].content[0].text.value\n",
    "                    completed = True\n",
    "                    # bstack.emit('chat.message', {'message': outgoingMessages})\n",
    "                    break\n",
    "\n",
    "                if response.status == 'requires_action':\n",
    "                    print('Run Action Required!')\n",
    "\n",
    "                    tool_outputs = []\n",
    "                    for ra in response.required_action.submit_tool_outputs.tool_calls:\n",
    "                        if ra.type == 'function' and ra.function.name in functions:\n",
    "                            print(f'Running {ra.function.name} with arguments {ra.function.arguments}')\n",
    "                            ret = functions[ra.function.name](ra.function.arguments)\n",
    "                            print('Returned', ret)\n",
    "                            tool_outputs.append({\n",
    "                                'tool_call_id': ra.id,\n",
    "                                'output': json.dumps(ret)\n",
    "                            })\n",
    "                        else:\n",
    "                            tool_outputs.append({\n",
    "                                'tool_call_id': ra.id,\n",
    "                                'output': 'There is a problem, function not found!'\n",
    "                            })\n",
    "\n",
    "                    run = openai.beta.threads.runs.submitToolOutputs(\n",
    "                        threadId,\n",
    "                        runId,\n",
    "                        {'tool_outputs': tool_outputs}\n",
    "                    )\n",
    "\n",
    "                if response.status in ('failed', 'cancelled', 'expired', 'cancelling'):\n",
    "                    print(f'Completed {response.status}')\n",
    "                    completed = True\n",
    "                    break\n",
    "\n",
    "                if response.status in ('in_progress', 'queued'):\n",
    "                    print(f'Run {response.status}')\n",
    "                    time.sleep(2)  # Poll every 2 seconds\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error in polling (retrying):', str(e))\n",
    "                # Handle the exception or retry logic as necessary\n",
    "\n",
    "pollAnswers(my_thread.id, my_run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24ad0245-c524-4e48-9fff-68c340c0be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_CN6GQDGwXgu3e9iKflUQtZVy', assistant_id='asst_uj4I5CHPcB2VRrBAlE9pjq48', cancelled_at=None, completed_at=None, created_at=1729638936, expires_at=1729639536, failed_at=None, incomplete_details=None, instructions='You are a clinical trial expert', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_817xEYjwWKciLwyoRm1qoSD4', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c05de-5b0c-4ba3-aae3-9b9a6cd0bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "service = OpenAIService(OPEN_AI_KEY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
